wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Agent Starting Run: 26zjgbh0 with config:
wandb: 	dummy: 100
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000519-26zjgbh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/26zjgbh0
Create sweep with ID: 2rqt856z
Sweep URL: https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
args = Namespace(dataset='pubmed', graph_name='pubmed-4-metis-vol-trans', model='graphsage', dropout=0.7565688403188127, lr=0.005, n_epochs=1000, n_partitions=4, n_hidden=256, n_layers=6, n_linear=0, norm='none', weight_decay=0, n_feat=500, n_class=3, n_train=60, skip_partition=False, partition_obj='vol', partition_method='metis', enable_pipeline=True, feat_corr=False, grad_corr=False, corr_momentum=0.95, convergence_threshold=1e-10, use_pp=True, inductive=False, fix_seed=False, seed=1420886996, log_every=5, patience=50, backend='gloo', port=18118, master_addr='127.0.0.1', node_rank=0, parts_per_node=10, eval=True)
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000539-26zjgbh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run enable_pipeline-True, n_hidden-256, n_layers-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/26zjgbh0
loading partitions
Process 3 has 5592 nodes, 36376 edges 5044 inner nodes, and 34586 inner edges.
Process 003 | Epoch 00004 | Time(s) 0.2165 | Comm(s) 0.0019 | Reduce(s) 0.1148 | Loss 0.9287
Process 003 | Epoch 00009 | Time(s) 0.2214 | Comm(s) 0.0012 | Reduce(s) 0.1113 | Loss 1.0887
Process 003 | Epoch 00014 | Time(s) 0.2216 | Comm(s) 0.0009 | Reduce(s) 0.1177 | Loss 1.0746
Process 003 | Epoch 00019 | Time(s) 0.2198 | Comm(s) 0.0010 | Reduce(s) 0.1183 | Loss 1.0092
Process 003 | Epoch 00024 | Time(s) 0.2198 | Comm(s) 0.0018 | Reduce(s) 0.1198 | Loss 0.9940
Process 003 | Epoch 00029 | Time(s) 0.2201 | Comm(s) 0.0019 | Reduce(s) 0.1221 | Loss 0.8714
Process 003 | Epoch 00034 | Time(s) 0.2197 | Comm(s) 0.0017 | Reduce(s) 0.1225 | Loss 0.9847
Process 003 | Epoch 00039 | Time(s) 0.2191 | Comm(s) 0.0019 | Reduce(s) 0.1239 | Loss 0.6219
Process 003 | Epoch 00044 | Time(s) 0.2195 | Comm(s) 0.0024 | Reduce(s) 0.1237 | Loss 0.5480
Process 003 | Epoch 00049 | Time(s) 0.2192 | Comm(s) 0.0032 | Reduce(s) 0.1201 | Loss 0.2640
Process 003 | Epoch 00054 | Time(s) 0.2199 | Comm(s) 0.0031 | Reduce(s) 0.1194 | Loss 0.0480
Process 003 | Epoch 00059 | Time(s) 0.2201 | Comm(s) 0.0030 | Reduce(s) 0.1214 | Loss 0.1183
Process 003 | Epoch 00064 | Time(s) 0.2194 | Comm(s) 0.0028 | Reduce(s) 0.1193 | Loss 0.0138
Early stopping after 65 epochs.
loading partitions
Process 1 has 5598 nodes, 23225 edges 4787 inner nodes, and 20303 inner edges.
Process 001 | Epoch 00004 | Time(s) 0.2176 | Comm(s) 0.0004 | Reduce(s) 0.1349 | Loss 1.1339
Process 001 | Epoch 00009 | Time(s) 0.2234 | Comm(s) 0.0004 | Reduce(s) 0.1520 | Loss 1.0198
Process 001 | Epoch 00014 | Time(s) 0.2228 | Comm(s) 0.0016 | Reduce(s) 0.1502 | Loss 1.0552
Process 001 | Epoch 00019 | Time(s) 0.2211 | Comm(s) 0.0013 | Reduce(s) 0.1460 | Loss 1.0143
Process 001 | Epoch 00024 | Time(s) 0.2210 | Comm(s) 0.0016 | Reduce(s) 0.1456 | Loss 0.8614
Process 001 | Epoch 00029 | Time(s) 0.2211 | Comm(s) 0.0018 | Reduce(s) 0.1453 | Loss 1.0418
Process 001 | Epoch 00034 | Time(s) 0.2206 | Comm(s) 0.0020 | Reduce(s) 0.1439 | Loss 0.4279
Process 001 | Epoch 00039 | Time(s) 0.2200 | Comm(s) 0.0021 | Reduce(s) 0.1439 | Loss 0.2737
Process 001 | Epoch 00044 | Time(s) 0.2207 | Comm(s) 0.0021 | Reduce(s) 0.1405 | Loss 0.1602
Process 001 | Epoch 00049 | Time(s) 0.2206 | Comm(s) 0.0020 | Reduce(s) 0.1413 | Loss 0.1798
Process 001 | Epoch 00054 | Time(s) 0.2212 | Comm(s) 0.0018 | Reduce(s) 0.1424 | Loss 0.0248
Process 001 | Epoch 00059 | Time(s) 0.2213 | Comm(s) 0.0019 | Reduce(s) 0.1410 | Loss 0.0010
Process 001 | Epoch 00064 | Time(s) 0.2207 | Comm(s) 0.0019 | Reduce(s) 0.1415 | Loss 0.0012
Early stopping after 65 epochs.
loading partitions
Process 2 has 5974 nodes, 29317 edges 4877 inner nodes, and 24861 inner edges.
Process 002 | Epoch 00004 | Time(s) 0.2142 | Comm(s) 0.0008 | Reduce(s) 0.0827 | Loss 1.2681
Process 002 | Epoch 00009 | Time(s) 0.2187 | Comm(s) 0.0007 | Reduce(s) 0.0448 | Loss 1.1616
Process 002 | Epoch 00014 | Time(s) 0.2191 | Comm(s) 0.0008 | Reduce(s) 0.0607 | Loss 1.1991
Process 002 | Epoch 00019 | Time(s) 0.2184 | Comm(s) 0.0008 | Reduce(s) 0.0704 | Loss 1.0736
Process 002 | Epoch 00024 | Time(s) 0.2189 | Comm(s) 0.0010 | Reduce(s) 0.0774 | Loss 0.9871
Process 002 | Epoch 00029 | Time(s) 0.2194 | Comm(s) 0.0014 | Reduce(s) 0.0812 | Loss 0.9703
Process 002 | Epoch 00034 | Time(s) 0.2190 | Comm(s) 0.0012 | Reduce(s) 0.0857 | Loss 0.6437
Process 002 | Epoch 00039 | Time(s) 0.2180 | Comm(s) 0.0011 | Reduce(s) 0.0858 | Loss 0.8565
Process 002 | Epoch 00044 | Time(s) 0.2186 | Comm(s) 0.0011 | Reduce(s) 0.0922 | Loss 0.3819
Process 002 | Epoch 00049 | Time(s) 0.2188 | Comm(s) 0.0011 | Reduce(s) 0.0954 | Loss 0.5836
Process 002 | Epoch 00054 | Time(s) 0.2195 | Comm(s) 0.0010 | Reduce(s) 0.0975 | Loss 0.0272
Process 002 | Epoch 00059 | Time(s) 0.2196 | Comm(s) 0.0010 | Reduce(s) 0.0973 | Loss 0.2582
Process 002 | Epoch 00064 | Time(s) 0.2191 | Comm(s) 0.0010 | Reduce(s) 0.0992 | Loss 0.0619
Early stopping after 65 epochs.
loading partitions
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
Process 0 has 5930 nodes, 26055 edges 5009 inner nodes, and 22007 inner edges.
Process 000 | Epoch 00004 | Time(s) 0.2215 | Comm(s) 0.0005 | Reduce(s) 0.0002 | Loss 0.7666
Process 000 | Epoch 00009 | Time(s) 0.2227 | Comm(s) 0.0005 | Reduce(s) 0.0343 | Loss 0.5314
Epoch 00004 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00014 | Time(s) 0.2148 | Comm(s) 0.0005 | Reduce(s) 0.0230 | Loss 0.6256
Epoch 00009 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00019 | Time(s) 0.2097 | Comm(s) 0.0067 | Reduce(s) 0.0173 | Loss 0.4626
Epoch 00014 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00024 | Time(s) 0.2072 | Comm(s) 0.0055 | Reduce(s) 0.0139 | Loss 0.6422
Epoch 00019 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00029 | Time(s) 0.2057 | Comm(s) 0.0046 | Reduce(s) 0.0117 | Loss 0.5980
Epoch 00024 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00034 | Time(s) 0.2038 | Comm(s) 0.0043 | Reduce(s) 0.0100 | Loss 0.5092
Epoch 00029 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00039 | Time(s) 0.2032 | Comm(s) 0.0038 | Reduce(s) 0.0088 | Loss 0.6321
Epoch 00034 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00044 | Time(s) 0.2031 | Comm(s) 0.0034 | Reduce(s) 0.0078 | Loss 0.1999
Epoch 00039 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00049 | Time(s) 0.2029 | Comm(s) 0.0031 | Reduce(s) 0.0071 | Loss 0.0590
Epoch 00044 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00054 | Time(s) 0.2030 | Comm(s) 0.0030 | Reduce(s) 0.0065 | Loss 0.2042
Epoch 00049 | Validation Accuracy 38.60% | Test Accuracy 41.60%
Process 000 | Epoch 00059 | Time(s) 0.2031 | Comm(s) 0.0033 | Reduce(s) 0.0060 | Loss 0.2499
Epoch 00054 | Validation Accuracy 38.20% | Test Accuracy 39.70%
Process 000 | Epoch 00064 | Time(s) 0.2024 | Comm(s) 0.0033 | Reduce(s) 0.0055 | Loss 0.7076
Epoch 00059 | Validation Accuracy 37.60% | Test Accuracy 41.10%
Early stopping after 65 epochs.
Epoch 00064 | Validation Accuracy 38.60% | Test Accuracy 40.20%
Validation accuracy 38.80%
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: average train time per epoch ‚ñÅ
wandb:                best_test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_test_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              best_train_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 best_val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                best_val_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   num epochs ‚ñÅ
wandb:                     test_acc ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñÅ‚ñÜ‚ñÉ
wandb:                    test_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ
wandb:                   torch_seed ‚ñà‚ñÅ
wandb:             total train time ‚ñÅ
wandb:     total train time per GPU ‚ñÅ
wandb:         train time per epoch ‚ñÅ
wandb:                    train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñà
wandb:                   train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ
wandb:                   train_time ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:                      val_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÖ‚ñÅ‚ñá
wandb:                     val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÖ
wandb: 
wandb: Run summary:
wandb: average train time per epoch 0.20237
wandb:                best_test_acc 0.413
wandb:               best_test_loss 1.31448
wandb:               best_train_acc 0.33333
wandb:              best_train_loss 1.77171
wandb:                 best_val_acc 0.388
wandb:                best_val_loss 1.37443
wandb:                   num epochs 65
wandb:                     test_acc 0.402
wandb:                    test_loss 14.76213
wandb:                   torch_seed 1420886996
wandb:             total train time 42.09326
wandb:     total train time per GPU 10.52332
wandb:         train time per epoch 0.64759
wandb:                    train_acc 0.43333
wandb:                   train_loss 22.82836
wandb:                   train_time 14.73197
wandb:                      val_acc 0.386
wandb:                     val_loss 16.4929
wandb: 
wandb: üöÄ View run light-sweep-1 at: https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/26zjgbh0
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230919_000519-26zjgbh0/logs
wandb: Agent Starting Run: 564e51sr with config:
wandb: 	dummy: 101
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000636-564e51sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/564e51sr
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
args = Namespace(dataset='pubmed', graph_name='pubmed-4-metis-vol-trans', model='graphsage', dropout=0.7565688403188127, lr=0.005, n_epochs=1000, n_partitions=4, n_hidden=256, n_layers=6, n_linear=0, norm='none', weight_decay=0, n_feat=500, n_class=3, n_train=60, skip_partition=False, partition_obj='vol', partition_method='metis', enable_pipeline=True, feat_corr=False, grad_corr=False, corr_momentum=0.95, convergence_threshold=1e-10, use_pp=True, inductive=False, fix_seed=False, seed=1518556063, log_every=5, patience=50, backend='gloo', port=18118, master_addr='127.0.0.1', node_rank=0, parts_per_node=10, eval=True)
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000654-564e51sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run enable_pipeline-True, n_hidden-256, n_layers-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/564e51sr
loading partitions
Process 2 has 5974 nodes, 29317 edges 4877 inner nodes, and 24861 inner edges.
Process 002 | Epoch 00004 | Time(s) 0.2131 | Comm(s) 0.0010 | Reduce(s) 0.0002 | Loss 1.0559
Process 002 | Epoch 00009 | Time(s) 0.2162 | Comm(s) 0.0007 | Reduce(s) 0.0640 | Loss 0.9169
Process 002 | Epoch 00014 | Time(s) 0.2149 | Comm(s) 0.0007 | Reduce(s) 0.0781 | Loss 1.2797
Process 002 | Epoch 00019 | Time(s) 0.2170 | Comm(s) 0.0007 | Reduce(s) 0.0871 | Loss 0.7493
Process 002 | Epoch 00024 | Time(s) 0.2170 | Comm(s) 0.0006 | Reduce(s) 0.0917 | Loss 0.6075
Process 002 | Epoch 00029 | Time(s) 0.2173 | Comm(s) 0.0006 | Reduce(s) 0.0931 | Loss 0.5705
Process 002 | Epoch 00034 | Time(s) 0.2182 | Comm(s) 0.0006 | Reduce(s) 0.0934 | Loss 0.4800
Process 002 | Epoch 00039 | Time(s) 0.2192 | Comm(s) 0.0006 | Reduce(s) 0.0974 | Loss 0.3948
Process 002 | Epoch 00044 | Time(s) 0.2207 | Comm(s) 0.0008 | Reduce(s) 0.0968 | Loss 0.4748
Process 002 | Epoch 00049 | Time(s) 0.2210 | Comm(s) 0.0009 | Reduce(s) 0.1010 | Loss 0.3351
Process 002 | Epoch 00054 | Time(s) 0.2207 | Comm(s) 0.0009 | Reduce(s) 0.1041 | Loss 0.2810
Process 002 | Epoch 00059 | Time(s) 0.2207 | Comm(s) 0.0009 | Reduce(s) 0.1046 | Loss 0.4439
Process 002 | Epoch 00064 | Time(s) 0.2206 | Comm(s) 0.0010 | Reduce(s) 0.1039 | Loss 0.2565
Process 002 | Epoch 00069 | Time(s) 0.2205 | Comm(s) 0.0010 | Reduce(s) 0.1044 | Loss 1.2816
Process 002 | Epoch 00074 | Time(s) 0.2205 | Comm(s) 0.0010 | Reduce(s) 0.1059 | Loss 1.6056
Early stopping after 75 epochs.
loading partitions
Process 1 has 5598 nodes, 23225 edges 4787 inner nodes, and 20303 inner edges.
Process 001 | Epoch 00004 | Time(s) 0.2050 | Comm(s) 0.0004 | Reduce(s) 0.1250 | Loss 1.0578
Process 001 | Epoch 00009 | Time(s) 0.2115 | Comm(s) 0.0018 | Reduce(s) 0.1135 | Loss 1.1073
Process 001 | Epoch 00014 | Time(s) 0.2130 | Comm(s) 0.0016 | Reduce(s) 0.1281 | Loss 1.2056
Process 001 | Epoch 00019 | Time(s) 0.2157 | Comm(s) 0.0014 | Reduce(s) 0.1309 | Loss 0.9156
Process 001 | Epoch 00024 | Time(s) 0.2159 | Comm(s) 0.0016 | Reduce(s) 0.1259 | Loss 0.9756
Process 001 | Epoch 00029 | Time(s) 0.2162 | Comm(s) 0.0014 | Reduce(s) 0.1282 | Loss 0.9108
Process 001 | Epoch 00034 | Time(s) 0.2173 | Comm(s) 0.0013 | Reduce(s) 0.1300 | Loss 0.7174
Process 001 | Epoch 00039 | Time(s) 0.2183 | Comm(s) 0.0012 | Reduce(s) 0.1312 | Loss 0.4727
Process 001 | Epoch 00044 | Time(s) 0.2200 | Comm(s) 0.0012 | Reduce(s) 0.1311 | Loss 0.4914
Process 001 | Epoch 00049 | Time(s) 0.2203 | Comm(s) 0.0011 | Reduce(s) 0.1286 | Loss 0.3140
Process 001 | Epoch 00054 | Time(s) 0.2200 | Comm(s) 0.0011 | Reduce(s) 0.1305 | Loss 0.2067
Process 001 | Epoch 00059 | Time(s) 0.2202 | Comm(s) 0.0010 | Reduce(s) 0.1313 | Loss 0.2171
Process 001 | Epoch 00064 | Time(s) 0.2200 | Comm(s) 0.0010 | Reduce(s) 0.1317 | Loss 0.1702
Process 001 | Epoch 00069 | Time(s) 0.2201 | Comm(s) 0.0010 | Reduce(s) 0.1332 | Loss 0.3015
Process 001 | Epoch 00074 | Time(s) 0.2200 | Comm(s) 0.0011 | Reduce(s) 0.1304 | Loss 0.0105
Early stopping after 75 epochs.
loading partitions
Process 3 has 5592 nodes, 36376 edges 5044 inner nodes, and 34586 inner edges.
Process 003 | Epoch 00004 | Time(s) 0.2044 | Comm(s) 0.0023 | Reduce(s) 0.0962 | Loss 0.9604
Process 003 | Epoch 00009 | Time(s) 0.2121 | Comm(s) 0.0014 | Reduce(s) 0.1045 | Loss 1.0727
Process 003 | Epoch 00014 | Time(s) 0.2129 | Comm(s) 0.0011 | Reduce(s) 0.1155 | Loss 0.9078
Process 003 | Epoch 00019 | Time(s) 0.2154 | Comm(s) 0.0009 | Reduce(s) 0.1236 | Loss 0.8323
Process 003 | Epoch 00024 | Time(s) 0.2156 | Comm(s) 0.0008 | Reduce(s) 0.1245 | Loss 0.6630
Process 003 | Epoch 00029 | Time(s) 0.2161 | Comm(s) 0.0007 | Reduce(s) 0.1272 | Loss 0.5764
Process 003 | Epoch 00034 | Time(s) 0.2173 | Comm(s) 0.0007 | Reduce(s) 0.1273 | Loss 0.3814
Process 003 | Epoch 00039 | Time(s) 0.2185 | Comm(s) 0.0007 | Reduce(s) 0.1269 | Loss 0.4773
Process 003 | Epoch 00044 | Time(s) 0.2202 | Comm(s) 0.0007 | Reduce(s) 0.1284 | Loss 0.0735
Process 003 | Epoch 00049 | Time(s) 0.2202 | Comm(s) 0.0007 | Reduce(s) 0.1253 | Loss 0.1796
Process 003 | Epoch 00054 | Time(s) 0.2199 | Comm(s) 0.0007 | Reduce(s) 0.1230 | Loss 0.0323
Process 003 | Epoch 00059 | Time(s) 0.2201 | Comm(s) 0.0007 | Reduce(s) 0.1221 | Loss 0.1052
Process 003 | Epoch 00064 | Time(s) 0.2200 | Comm(s) 0.0007 | Reduce(s) 0.1225 | Loss 0.2470
Process 003 | Epoch 00069 | Time(s) 0.2200 | Comm(s) 0.0008 | Reduce(s) 0.1208 | Loss 0.2458
Process 003 | Epoch 00074 | Time(s) 0.2201 | Comm(s) 0.0008 | Reduce(s) 0.1213 | Loss 0.0441
Early stopping after 75 epochs.
loading partitions
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
Process 0 has 5930 nodes, 26055 edges 5009 inner nodes, and 22007 inner edges.
Process 000 | Epoch 00004 | Time(s) 0.2038 | Comm(s) 0.0005 | Reduce(s) 0.0807 | Loss 1.5649
Process 000 | Epoch 00009 | Time(s) 0.2016 | Comm(s) 0.0005 | Reduce(s) 0.0407 | Loss 1.1551
Epoch 00004 | Validation Accuracy 41.60% | Test Accuracy 40.70%
Process 000 | Epoch 00014 | Time(s) 0.1914 | Comm(s) 0.0009 | Reduce(s) 0.0272 | Loss 1.1187
Epoch 00009 | Validation Accuracy 41.60% | Test Accuracy 40.70%
Process 000 | Epoch 00019 | Time(s) 0.1888 | Comm(s) 0.0008 | Reduce(s) 0.0205 | Loss 1.0953
Epoch 00014 | Validation Accuracy 41.60% | Test Accuracy 40.70%
Process 000 | Epoch 00024 | Time(s) 0.1902 | Comm(s) 0.0007 | Reduce(s) 0.0164 | Loss 0.9769
Epoch 00019 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00029 | Time(s) 0.1905 | Comm(s) 0.0020 | Reduce(s) 0.0137 | Loss 0.7835
Epoch 00024 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00034 | Time(s) 0.1923 | Comm(s) 0.0018 | Reduce(s) 0.0118 | Loss 0.6162
Epoch 00029 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00039 | Time(s) 0.1920 | Comm(s) 0.0017 | Reduce(s) 0.0104 | Loss 0.5503
Epoch 00034 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00044 | Time(s) 0.1943 | Comm(s) 0.0015 | Reduce(s) 0.0092 | Loss 0.6326
Epoch 00039 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00049 | Time(s) 0.1960 | Comm(s) 0.0015 | Reduce(s) 0.0083 | Loss 1.1520
Epoch 00044 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00054 | Time(s) 0.1948 | Comm(s) 0.0015 | Reduce(s) 0.0076 | Loss 0.9938
Epoch 00049 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00059 | Time(s) 0.1951 | Comm(s) 0.0023 | Reduce(s) 0.0070 | Loss 0.4538
Epoch 00054 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00064 | Time(s) 0.1957 | Comm(s) 0.0023 | Reduce(s) 0.0065 | Loss 0.9983
Epoch 00059 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00069 | Time(s) 0.1962 | Comm(s) 0.0028 | Reduce(s) 0.0060 | Loss 0.5075
Epoch 00064 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00074 | Time(s) 0.1967 | Comm(s) 0.0026 | Reduce(s) 0.0056 | Loss 0.5838
Epoch 00069 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Early stopping after 75 epochs.
Epoch 00074 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Validation accuracy 41.60%
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: average train time per epoch ‚ñÅ
wandb:                best_test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_test_loss ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              best_train_loss ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 best_val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                best_val_loss ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   num epochs ‚ñÅ
wandb:                     test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                    test_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñÜ
wandb:                   torch_seed ‚ñà‚ñÅ
wandb:             total train time ‚ñÅ
wandb:     total train time per GPU ‚ñÅ
wandb:         train time per epoch ‚ñÅ
wandb:                    train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÜ
wandb:                   train_time ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà
wandb:                      val_acc ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                     val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb: average train time per epoch 0.19669
wandb:                best_test_acc 0.407
wandb:               best_test_loss 1.0952
wandb:               best_train_acc 0.33333
wandb:              best_train_loss 1.09926
wandb:                 best_val_acc 0.416
wandb:                best_val_loss 1.09678
wandb:                   num epochs 75
wandb:                     test_acc 0.413
wandb:                    test_loss 1.91357
wandb:                   torch_seed 1518556063
wandb:             total train time 47.2053
wandb:     total train time per GPU 11.80133
wandb:         train time per epoch 0.6294
wandb:                    train_acc 0.33333
wandb:                   train_loss 2.53538
wandb:                   train_time 16.41136
wandb:                      val_acc 0.388
wandb:                     val_loss 2.04036
wandb: 
wandb: üöÄ View run zany-sweep-2 at: https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/564e51sr
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230919_000636-564e51sr/logs
wandb: Agent Starting Run: fdkh39px with config:
wandb: 	dummy: 102
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000746-fdkh39px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/fdkh39px
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
args = Namespace(dataset='pubmed', graph_name='pubmed-4-metis-vol-trans', model='graphsage', dropout=0.7565688403188127, lr=0.005, n_epochs=1000, n_partitions=4, n_hidden=256, n_layers=6, n_linear=0, norm='none', weight_decay=0, n_feat=500, n_class=3, n_train=60, skip_partition=False, partition_obj='vol', partition_method='metis', enable_pipeline=True, feat_corr=False, grad_corr=False, corr_momentum=0.95, convergence_threshold=1e-10, use_pp=True, inductive=False, fix_seed=False, seed=453380795, log_every=5, patience=50, backend='gloo', port=18118, master_addr='127.0.0.1', node_rank=0, parts_per_node=10, eval=True)
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000802-fdkh39px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run enable_pipeline-True, n_hidden-256, n_layers-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/fdkh39px
loading partitions
Process 2 has 5974 nodes, 29317 edges 4877 inner nodes, and 24861 inner edges.
Process 002 | Epoch 00004 | Time(s) 0.2118 | Comm(s) 0.0023 | Reduce(s) 0.0753 | Loss 1.4184
Process 002 | Epoch 00009 | Time(s) 0.2210 | Comm(s) 0.0025 | Reduce(s) 0.0830 | Loss 1.0710
Process 002 | Epoch 00014 | Time(s) 0.2260 | Comm(s) 0.0018 | Reduce(s) 0.0930 | Loss 1.3471
Process 002 | Epoch 00019 | Time(s) 0.2250 | Comm(s) 0.0016 | Reduce(s) 0.0958 | Loss 1.2421
Process 002 | Epoch 00024 | Time(s) 0.2236 | Comm(s) 0.0014 | Reduce(s) 0.1025 | Loss 1.1299
Process 002 | Epoch 00029 | Time(s) 0.2232 | Comm(s) 0.0012 | Reduce(s) 0.1066 | Loss 1.0379
Process 002 | Epoch 00034 | Time(s) 0.2228 | Comm(s) 0.0011 | Reduce(s) 0.1060 | Loss 0.8160
Process 002 | Epoch 00039 | Time(s) 0.2226 | Comm(s) 0.0010 | Reduce(s) 0.1100 | Loss 0.7588
Process 002 | Epoch 00044 | Time(s) 0.2222 | Comm(s) 0.0009 | Reduce(s) 0.1073 | Loss 0.4274
Process 002 | Epoch 00049 | Time(s) 0.2225 | Comm(s) 0.0012 | Reduce(s) 0.1068 | Loss 1.5934
Process 002 | Epoch 00054 | Time(s) 0.2225 | Comm(s) 0.0012 | Reduce(s) 0.1091 | Loss 0.5438
Process 002 | Epoch 00059 | Time(s) 0.2228 | Comm(s) 0.0012 | Reduce(s) 0.1126 | Loss 0.8572
Process 002 | Epoch 00064 | Time(s) 0.2223 | Comm(s) 0.0012 | Reduce(s) 0.1138 | Loss 0.2976
Early stopping after 65 epochs.
loading partitions
Process 1 has 5598 nodes, 23225 edges 4787 inner nodes, and 20303 inner edges.
Process 001 | Epoch 00004 | Time(s) 0.2142 | Comm(s) 0.0017 | Reduce(s) 0.1308 | Loss 0.8609
Process 001 | Epoch 00009 | Time(s) 0.2243 | Comm(s) 0.0037 | Reduce(s) 0.1367 | Loss 1.0249
Process 001 | Epoch 00014 | Time(s) 0.2283 | Comm(s) 0.0029 | Reduce(s) 0.1408 | Loss 1.0574
Process 001 | Epoch 00019 | Time(s) 0.2267 | Comm(s) 0.0023 | Reduce(s) 0.1355 | Loss 0.9987
Process 001 | Epoch 00024 | Time(s) 0.2247 | Comm(s) 0.0019 | Reduce(s) 0.1268 | Loss 0.8804
Process 001 | Epoch 00029 | Time(s) 0.2240 | Comm(s) 0.0018 | Reduce(s) 0.1251 | Loss 0.5759
Process 001 | Epoch 00034 | Time(s) 0.2237 | Comm(s) 0.0017 | Reduce(s) 0.1257 | Loss 0.3216
Process 001 | Epoch 00039 | Time(s) 0.2230 | Comm(s) 0.0015 | Reduce(s) 0.1220 | Loss 0.1950
Process 001 | Epoch 00044 | Time(s) 0.2236 | Comm(s) 0.0014 | Reduce(s) 0.1254 | Loss 0.1605
Process 001 | Epoch 00049 | Time(s) 0.2238 | Comm(s) 0.0013 | Reduce(s) 0.1267 | Loss 0.3522
Process 001 | Epoch 00054 | Time(s) 0.2236 | Comm(s) 0.0012 | Reduce(s) 0.1288 | Loss 0.3303
Process 001 | Epoch 00059 | Time(s) 0.2238 | Comm(s) 0.0012 | Reduce(s) 0.1288 | Loss 0.1032
Process 001 | Epoch 00064 | Time(s) 0.2232 | Comm(s) 0.0012 | Reduce(s) 0.1265 | Loss 0.3522
Early stopping after 65 epochs.
loading partitions
Process 3 has 5592 nodes, 36376 edges 5044 inner nodes, and 34586 inner edges.
Process 003 | Epoch 00004 | Time(s) 0.2146 | Comm(s) 0.0004 | Reduce(s) 0.1091 | Loss 0.9278
Process 003 | Epoch 00009 | Time(s) 0.2244 | Comm(s) 0.0005 | Reduce(s) 0.1205 | Loss 1.3112
Process 003 | Epoch 00014 | Time(s) 0.2282 | Comm(s) 0.0011 | Reduce(s) 0.1321 | Loss 0.9898
Process 003 | Epoch 00019 | Time(s) 0.2266 | Comm(s) 0.0011 | Reduce(s) 0.1368 | Loss 1.0974
Process 003 | Epoch 00024 | Time(s) 0.2251 | Comm(s) 0.0010 | Reduce(s) 0.1353 | Loss 1.1899
Process 003 | Epoch 00029 | Time(s) 0.2244 | Comm(s) 0.0009 | Reduce(s) 0.1330 | Loss 0.9516
Process 003 | Epoch 00034 | Time(s) 0.2239 | Comm(s) 0.0009 | Reduce(s) 0.1355 | Loss 0.7902
Process 003 | Epoch 00039 | Time(s) 0.2235 | Comm(s) 0.0010 | Reduce(s) 0.1355 | Loss 0.6510
Process 003 | Epoch 00044 | Time(s) 0.2240 | Comm(s) 0.0010 | Reduce(s) 0.1351 | Loss 0.8848
Process 003 | Epoch 00049 | Time(s) 0.2241 | Comm(s) 0.0010 | Reduce(s) 0.1363 | Loss 0.4281
Process 003 | Epoch 00054 | Time(s) 0.2240 | Comm(s) 0.0010 | Reduce(s) 0.1340 | Loss 0.4550
Process 003 | Epoch 00059 | Time(s) 0.2238 | Comm(s) 0.0009 | Reduce(s) 0.1307 | Loss 0.2021
Process 003 | Epoch 00064 | Time(s) 0.2233 | Comm(s) 0.0009 | Reduce(s) 0.1302 | Loss 0.2053
Early stopping after 65 epochs.
loading partitions
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
Process 0 has 5930 nodes, 26055 edges 5009 inner nodes, and 22007 inner edges.
Process 000 | Epoch 00004 | Time(s) 0.2177 | Comm(s) 0.0027 | Reduce(s) 0.0002 | Loss 0.9841
Process 000 | Epoch 00009 | Time(s) 0.2239 | Comm(s) 0.0016 | Reduce(s) 0.0002 | Loss 0.3409
Epoch 00004 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00014 | Time(s) 0.2187 | Comm(s) 0.0015 | Reduce(s) 0.0002 | Loss 0.8061
Epoch 00009 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00019 | Time(s) 0.2143 | Comm(s) 0.0013 | Reduce(s) 0.0004 | Loss 0.7118
Epoch 00014 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00024 | Time(s) 0.2116 | Comm(s) 0.0011 | Reduce(s) 0.0004 | Loss 0.5451
Epoch 00019 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00029 | Time(s) 0.2090 | Comm(s) 0.0013 | Reduce(s) 0.0003 | Loss 0.5630
Epoch 00024 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00034 | Time(s) 0.2062 | Comm(s) 0.0023 | Reduce(s) 0.0003 | Loss 0.3150
Epoch 00029 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00039 | Time(s) 0.2048 | Comm(s) 0.0035 | Reduce(s) 0.0003 | Loss 0.5279
Epoch 00034 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00044 | Time(s) 0.2057 | Comm(s) 0.0037 | Reduce(s) 0.0003 | Loss 0.1314
Epoch 00039 | Validation Accuracy 39.60% | Test Accuracy 41.70%
Process 000 | Epoch 00049 | Time(s) 0.2050 | Comm(s) 0.0035 | Reduce(s) 0.0004 | Loss 0.1212
Epoch 00044 | Validation Accuracy 38.80% | Test Accuracy 41.20%
Process 000 | Epoch 00054 | Time(s) 0.2024 | Comm(s) 0.0041 | Reduce(s) 0.0003 | Loss 0.0350
Epoch 00049 | Validation Accuracy 38.80% | Test Accuracy 42.30%
Process 000 | Epoch 00059 | Time(s) 0.2027 | Comm(s) 0.0038 | Reduce(s) 0.0003 | Loss 0.3099
Epoch 00054 | Validation Accuracy 39.00% | Test Accuracy 41.40%
Process 000 | Epoch 00064 | Time(s) 0.2021 | Comm(s) 0.0041 | Reduce(s) 0.0003 | Loss 0.8203
Epoch 00059 | Validation Accuracy 44.00% | Test Accuracy 41.90%
Early stopping after 65 epochs.
Epoch 00064 | Validation Accuracy 41.60% | Test Accuracy 41.80%
Validation accuracy 44.00%
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: average train time per epoch ‚ñÅ
wandb:                best_test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñà
wandb:               best_test_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñà
wandb:              best_train_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 best_val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñà
wandb:                best_val_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   num epochs ‚ñÅ
wandb:                     test_acc ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÅ‚ñà‚ñÇ‚ñÖ‚ñÖ
wandb:                    test_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ
wandb:                   torch_seed ‚ñà‚ñÅ
wandb:             total train time ‚ñÅ
wandb:     total train time per GPU ‚ñÅ
wandb:         train time per epoch ‚ñÅ
wandb:                    train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñà‚ñà
wandb:                   train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ
wandb:                   train_time ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:                      val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ
wandb:                     val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb: average train time per epoch 0.20208
wandb:                best_test_acc 0.419
wandb:               best_test_loss 1.69113
wandb:               best_train_acc 0.48333
wandb:              best_train_loss 2.35587
wandb:                 best_val_acc 0.44
wandb:                best_val_loss 1.7841
wandb:                   num epochs 65
wandb:                     test_acc 0.418
wandb:                    test_loss 36.81473
wandb:                   torch_seed 453380795
wandb:             total train time 42.03288
wandb:     total train time per GPU 10.50822
wandb:         train time per epoch 0.64666
wandb:                    train_acc 0.48333
wandb:                   train_loss 60.77134
wandb:                   train_time 14.66397
wandb:                      val_acc 0.416
wandb:                     val_loss 41.89859
wandb: 
wandb: üöÄ View run vocal-sweep-3 at: https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/fdkh39px
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230919_000746-fdkh39px/logs
wandb: Agent Starting Run: akqu8x6m with config:
wandb: 	dummy: 103
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000852-akqu8x6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/akqu8x6m
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
args = Namespace(dataset='pubmed', graph_name='pubmed-4-metis-vol-trans', model='graphsage', dropout=0.7565688403188127, lr=0.005, n_epochs=1000, n_partitions=4, n_hidden=256, n_layers=6, n_linear=0, norm='none', weight_decay=0, n_feat=500, n_class=3, n_train=60, skip_partition=False, partition_obj='vol', partition_method='metis', enable_pipeline=True, feat_corr=False, grad_corr=False, corr_momentum=0.95, convergence_threshold=1e-10, use_pp=True, inductive=False, fix_seed=False, seed=1530541778, log_every=5, patience=50, backend='gloo', port=18118, master_addr='127.0.0.1', node_rank=0, parts_per_node=10, eval=True)
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000912-akqu8x6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run enable_pipeline-True, n_hidden-256, n_layers-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/akqu8x6m
loading partitions
Process 1 has 5598 nodes, 23225 edges 4787 inner nodes, and 20303 inner edges.
Process 001 | Epoch 00004 | Time(s) 0.2307 | Comm(s) 0.0009 | Reduce(s) 0.1480 | Loss 1.0976
Process 001 | Epoch 00009 | Time(s) 0.2240 | Comm(s) 0.0006 | Reduce(s) 0.1610 | Loss 1.0621
Process 001 | Epoch 00014 | Time(s) 0.2199 | Comm(s) 0.0006 | Reduce(s) 0.1537 | Loss 0.9266
Process 001 | Epoch 00019 | Time(s) 0.2202 | Comm(s) 0.0005 | Reduce(s) 0.1530 | Loss 1.0378
Process 001 | Epoch 00024 | Time(s) 0.2199 | Comm(s) 0.0013 | Reduce(s) 0.1476 | Loss 0.9223
Process 001 | Epoch 00029 | Time(s) 0.2199 | Comm(s) 0.0011 | Reduce(s) 0.1487 | Loss 0.7487
Process 001 | Epoch 00034 | Time(s) 0.2203 | Comm(s) 0.0010 | Reduce(s) 0.1446 | Loss 0.5404
Process 001 | Epoch 00039 | Time(s) 0.2199 | Comm(s) 0.0009 | Reduce(s) 0.1441 | Loss 0.4369
Process 001 | Epoch 00044 | Time(s) 0.2189 | Comm(s) 0.0009 | Reduce(s) 0.1391 | Loss 0.3246
Process 001 | Epoch 00049 | Time(s) 0.2190 | Comm(s) 0.0008 | Reduce(s) 0.1407 | Loss 0.2126
Process 001 | Epoch 00054 | Time(s) 0.2190 | Comm(s) 0.0009 | Reduce(s) 0.1400 | Loss 0.1175
Process 001 | Epoch 00059 | Time(s) 0.2192 | Comm(s) 0.0009 | Reduce(s) 0.1398 | Loss 0.0142
Early stopping after 60 epochs.
loading partitions
Process 2 has 5974 nodes, 29317 edges 4877 inner nodes, and 24861 inner edges.
Process 002 | Epoch 00004 | Time(s) 0.2315 | Comm(s) 0.0034 | Reduce(s) 0.0031 | Loss 0.8342
Process 002 | Epoch 00009 | Time(s) 0.2153 | Comm(s) 0.0041 | Reduce(s) 0.0457 | Loss 0.9519
Process 002 | Epoch 00014 | Time(s) 0.2132 | Comm(s) 0.0033 | Reduce(s) 0.0617 | Loss 0.7601
Process 002 | Epoch 00019 | Time(s) 0.2152 | Comm(s) 0.0027 | Reduce(s) 0.0707 | Loss 0.7787
Process 002 | Epoch 00024 | Time(s) 0.2158 | Comm(s) 0.0023 | Reduce(s) 0.0777 | Loss 0.5073
Process 002 | Epoch 00029 | Time(s) 0.2158 | Comm(s) 0.0020 | Reduce(s) 0.0797 | Loss 0.4412
Process 002 | Epoch 00034 | Time(s) 0.2167 | Comm(s) 0.0020 | Reduce(s) 0.0852 | Loss 0.3532
Process 002 | Epoch 00039 | Time(s) 0.2166 | Comm(s) 0.0034 | Reduce(s) 0.0865 | Loss 0.3659
Process 002 | Epoch 00044 | Time(s) 0.2163 | Comm(s) 0.0034 | Reduce(s) 0.0884 | Loss 0.2848
Process 002 | Epoch 00049 | Time(s) 0.2166 | Comm(s) 0.0032 | Reduce(s) 0.0923 | Loss 0.3646
Process 002 | Epoch 00054 | Time(s) 0.2168 | Comm(s) 0.0029 | Reduce(s) 0.0961 | Loss 0.2031
Process 002 | Epoch 00059 | Time(s) 0.2172 | Comm(s) 0.0027 | Reduce(s) 0.0962 | Loss 0.0485
Early stopping after 60 epochs.
loading partitions
Process 3 has 5592 nodes, 36376 edges 5044 inner nodes, and 34586 inner edges.
Process 003 | Epoch 00004 | Time(s) 0.2309 | Comm(s) 0.0017 | Reduce(s) 0.1264 | Loss 0.8867
Process 003 | Epoch 00009 | Time(s) 0.2233 | Comm(s) 0.0038 | Reduce(s) 0.1342 | Loss 0.9684
Process 003 | Epoch 00014 | Time(s) 0.2195 | Comm(s) 0.0033 | Reduce(s) 0.1327 | Loss 0.7593
Process 003 | Epoch 00019 | Time(s) 0.2200 | Comm(s) 0.0026 | Reduce(s) 0.1280 | Loss 0.9218
Process 003 | Epoch 00024 | Time(s) 0.2198 | Comm(s) 0.0027 | Reduce(s) 0.1278 | Loss 0.5498
Process 003 | Epoch 00029 | Time(s) 0.2199 | Comm(s) 0.0026 | Reduce(s) 0.1284 | Loss 0.4486
Process 003 | Epoch 00034 | Time(s) 0.2202 | Comm(s) 0.0024 | Reduce(s) 0.1264 | Loss 0.4821
Process 003 | Epoch 00039 | Time(s) 0.2200 | Comm(s) 0.0022 | Reduce(s) 0.1269 | Loss 0.3626
Process 003 | Epoch 00044 | Time(s) 0.2193 | Comm(s) 0.0021 | Reduce(s) 0.1289 | Loss 0.3247
Process 003 | Epoch 00049 | Time(s) 0.2184 | Comm(s) 0.0022 | Reduce(s) 0.1245 | Loss 0.0270
Process 003 | Epoch 00054 | Time(s) 0.2183 | Comm(s) 0.0020 | Reduce(s) 0.1218 | Loss 1.0104
Process 003 | Epoch 00059 | Time(s) 0.2187 | Comm(s) 0.0020 | Reduce(s) 0.1230 | Loss 0.0736
Early stopping after 60 epochs.
loading partitions
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
Process 0 has 5930 nodes, 26055 edges 5009 inner nodes, and 22007 inner edges.
Process 000 | Epoch 00004 | Time(s) 0.2293 | Comm(s) 0.0008 | Reduce(s) 0.0117 | Loss 1.0887
Process 000 | Epoch 00009 | Time(s) 0.2084 | Comm(s) 0.0008 | Reduce(s) 0.0060 | Loss 0.7121
Epoch 00004 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00014 | Time(s) 0.2018 | Comm(s) 0.0007 | Reduce(s) 0.0041 | Loss 1.0801
Epoch 00009 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00019 | Time(s) 0.2023 | Comm(s) 0.0006 | Reduce(s) 0.0031 | Loss 0.5615
Epoch 00014 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00024 | Time(s) 0.2017 | Comm(s) 0.0011 | Reduce(s) 0.0025 | Loss 0.6538
Epoch 00019 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00029 | Time(s) 0.2001 | Comm(s) 0.0012 | Reduce(s) 0.0021 | Loss 0.8373
Epoch 00024 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00034 | Time(s) 0.2004 | Comm(s) 0.0040 | Reduce(s) 0.0019 | Loss 0.6448
Epoch 00029 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00039 | Time(s) 0.2003 | Comm(s) 0.0036 | Reduce(s) 0.0017 | Loss 0.7796
Epoch 00034 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00044 | Time(s) 0.2004 | Comm(s) 0.0033 | Reduce(s) 0.0015 | Loss 0.3672
Epoch 00039 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00049 | Time(s) 0.2005 | Comm(s) 0.0032 | Reduce(s) 0.0014 | Loss 0.2934
Epoch 00044 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00054 | Time(s) 0.2002 | Comm(s) 0.0030 | Reduce(s) 0.0013 | Loss 0.3811
Epoch 00049 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00059 | Time(s) 0.2001 | Comm(s) 0.0028 | Reduce(s) 0.0012 | Loss 0.2206
Epoch 00054 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Early stopping after 60 epochs.
Epoch 00059 | Validation Accuracy 35.80% | Test Accuracy 38.10%
Validation accuracy 38.80%
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: | 0.003 MB of 0.010 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: average train time per epoch ‚ñÅ
wandb:                best_test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_test_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:              best_train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 best_val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                best_val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   num epochs ‚ñÅ
wandb:                     test_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:                    test_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÜ
wandb:                   torch_seed ‚ñà‚ñÅ
wandb:             total train time ‚ñÅ
wandb:     total train time per GPU ‚ñÅ
wandb:         train time per epoch ‚ñÅ
wandb:                    train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà
wandb:                   train_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñà‚ñÜ
wandb:                   train_time ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:                      val_acc ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:                     val_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÜ
wandb: 
wandb: Run summary:
wandb: average train time per epoch 0.20007
wandb:                best_test_acc 0.413
wandb:               best_test_loss 1.12295
wandb:               best_train_acc 0.33333
wandb:              best_train_loss 1.10544
wandb:                 best_val_acc 0.388
wandb:                best_val_loss 1.12563
wandb:                   num epochs 60
wandb:                     test_acc 0.381
wandb:                    test_loss 9.06399
wandb:                   torch_seed 1530541778
wandb:             total train time 38.41262
wandb:     total train time per GPU 9.60316
wandb:         train time per epoch 0.64021
wandb:                    train_acc 0.36667
wandb:                   train_loss 11.91618
wandb:                   train_time 13.45088
wandb:                      val_acc 0.358
wandb:                     val_loss 10.0701
wandb: 
wandb: üöÄ View run confused-sweep-4 at: https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/akqu8x6m
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230919_000852-akqu8x6m/logs
wandb: Agent Starting Run: 27m1gn39 with config:
wandb: 	dummy: 104
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_000958-27m1gn39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/27m1gn39
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
args = Namespace(dataset='pubmed', graph_name='pubmed-4-metis-vol-trans', model='graphsage', dropout=0.7565688403188127, lr=0.005, n_epochs=1000, n_partitions=4, n_hidden=256, n_layers=6, n_linear=0, norm='none', weight_decay=0, n_feat=500, n_class=3, n_train=60, skip_partition=False, partition_obj='vol', partition_method='metis', enable_pipeline=True, feat_corr=False, grad_corr=False, corr_momentum=0.95, convergence_threshold=1e-10, use_pp=True, inductive=False, fix_seed=False, seed=218502625, log_every=5, patience=50, backend='gloo', port=18118, master_addr='127.0.0.1', node_rank=0, parts_per_node=10, eval=True)
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: sbajaj (rl_project_saurabh_arundhati). Use `wandb login --relogin` to force relogin
wandb: WARNING Ignored wandb.init() arg project when running a sweep.
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /work/sbajaj_umass_edu/GNN_minibatch_vs_fullbatch/PipeGCN/wandb/run-20230919_001014-27m1gn39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run enable_pipeline-True, n_hidden-256, n_layers-6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage
wandb: üßπ View sweep at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/sweeps/2rqt856z
wandb: üöÄ View run at https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/27m1gn39
loading partitions
Process 1 has 5598 nodes, 23225 edges 4787 inner nodes, and 20303 inner edges.
Process 001 | Epoch 00004 | Time(s) 0.2202 | Comm(s) 0.0004 | Reduce(s) 0.1350 | Loss 1.0660
Process 001 | Epoch 00009 | Time(s) 0.2182 | Comm(s) 0.0006 | Reduce(s) 0.1441 | Loss 1.0169
Process 001 | Epoch 00014 | Time(s) 0.2164 | Comm(s) 0.0007 | Reduce(s) 0.1443 | Loss 0.8763
Process 001 | Epoch 00019 | Time(s) 0.2183 | Comm(s) 0.0016 | Reduce(s) 0.1448 | Loss 0.8383
Process 001 | Epoch 00024 | Time(s) 0.2180 | Comm(s) 0.0015 | Reduce(s) 0.1425 | Loss 0.3307
Process 001 | Epoch 00029 | Time(s) 0.2171 | Comm(s) 0.0013 | Reduce(s) 0.1396 | Loss 0.2574
Process 001 | Epoch 00034 | Time(s) 0.2173 | Comm(s) 0.0013 | Reduce(s) 0.1377 | Loss 0.2157
Process 001 | Epoch 00039 | Time(s) 0.2178 | Comm(s) 0.0012 | Reduce(s) 0.1336 | Loss 0.1803
Process 001 | Epoch 00044 | Time(s) 0.2181 | Comm(s) 0.0011 | Reduce(s) 0.1351 | Loss 0.1336
Process 001 | Epoch 00049 | Time(s) 0.2190 | Comm(s) 0.0010 | Reduce(s) 0.1333 | Loss 0.1583
Process 001 | Epoch 00054 | Time(s) 0.2188 | Comm(s) 0.0010 | Reduce(s) 0.1340 | Loss 0.2269
Process 001 | Epoch 00059 | Time(s) 0.2189 | Comm(s) 0.0010 | Reduce(s) 0.1341 | Loss 0.1104
Process 001 | Epoch 00064 | Time(s) 0.2190 | Comm(s) 0.0010 | Reduce(s) 0.1339 | Loss 0.0654
Early stopping after 65 epochs.
loading partitions
Process 3 has 5592 nodes, 36376 edges 5044 inner nodes, and 34586 inner edges.
Process 003 | Epoch 00004 | Time(s) 0.2209 | Comm(s) 0.0010 | Reduce(s) 0.1110 | Loss 0.9511
Process 003 | Epoch 00009 | Time(s) 0.2185 | Comm(s) 0.0012 | Reduce(s) 0.1182 | Loss 1.1584
Process 003 | Epoch 00014 | Time(s) 0.2166 | Comm(s) 0.0013 | Reduce(s) 0.1233 | Loss 1.0666
Process 003 | Epoch 00019 | Time(s) 0.2185 | Comm(s) 0.0011 | Reduce(s) 0.1240 | Loss 1.0211
Process 003 | Epoch 00024 | Time(s) 0.2182 | Comm(s) 0.0016 | Reduce(s) 0.1254 | Loss 0.9469
Process 003 | Epoch 00029 | Time(s) 0.2170 | Comm(s) 0.0015 | Reduce(s) 0.1200 | Loss 0.7928
Process 003 | Epoch 00034 | Time(s) 0.2174 | Comm(s) 0.0016 | Reduce(s) 0.1192 | Loss 0.6104
Process 003 | Epoch 00039 | Time(s) 0.2179 | Comm(s) 0.0015 | Reduce(s) 0.1214 | Loss 1.2289
Process 003 | Epoch 00044 | Time(s) 0.2183 | Comm(s) 0.0014 | Reduce(s) 0.1239 | Loss 0.6126
Process 003 | Epoch 00049 | Time(s) 0.2190 | Comm(s) 0.0017 | Reduce(s) 0.1200 | Loss 0.2666
Process 003 | Epoch 00054 | Time(s) 0.2188 | Comm(s) 0.0017 | Reduce(s) 0.1180 | Loss 0.1321
Process 003 | Epoch 00059 | Time(s) 0.2188 | Comm(s) 0.0016 | Reduce(s) 0.1161 | Loss 0.2478
Process 003 | Epoch 00064 | Time(s) 0.2189 | Comm(s) 0.0015 | Reduce(s) 0.1165 | Loss 0.0262
Early stopping after 65 epochs.
loading partitions
Process 2 has 5974 nodes, 29317 edges 4877 inner nodes, and 24861 inner edges.
Process 002 | Epoch 00004 | Time(s) 0.2172 | Comm(s) 0.0008 | Reduce(s) 0.0648 | Loss 1.3708
Process 002 | Epoch 00009 | Time(s) 0.2139 | Comm(s) 0.0047 | Reduce(s) 0.0773 | Loss 1.2543
Process 002 | Epoch 00014 | Time(s) 0.2126 | Comm(s) 0.0035 | Reduce(s) 0.0840 | Loss 1.2877
Process 002 | Epoch 00019 | Time(s) 0.2154 | Comm(s) 0.0028 | Reduce(s) 0.0877 | Loss 1.1155
Process 002 | Epoch 00024 | Time(s) 0.2153 | Comm(s) 0.0023 | Reduce(s) 0.0884 | Loss 0.6892
Process 002 | Epoch 00029 | Time(s) 0.2148 | Comm(s) 0.0024 | Reduce(s) 0.0962 | Loss 0.6852
Process 002 | Epoch 00034 | Time(s) 0.2154 | Comm(s) 0.0021 | Reduce(s) 0.1023 | Loss 0.7410
Process 002 | Epoch 00039 | Time(s) 0.2162 | Comm(s) 0.0019 | Reduce(s) 0.1080 | Loss 0.7062
Process 002 | Epoch 00044 | Time(s) 0.2161 | Comm(s) 0.0018 | Reduce(s) 0.1060 | Loss 0.5479
Process 002 | Epoch 00049 | Time(s) 0.2174 | Comm(s) 0.0016 | Reduce(s) 0.1107 | Loss 0.4426
Process 002 | Epoch 00054 | Time(s) 0.2173 | Comm(s) 0.0016 | Reduce(s) 0.1124 | Loss 0.9321
Process 002 | Epoch 00059 | Time(s) 0.2175 | Comm(s) 0.0017 | Reduce(s) 0.1134 | Loss 0.0634
Process 002 | Epoch 00064 | Time(s) 0.2177 | Comm(s) 0.0017 | Reduce(s) 0.1130 | Loss 0.0643
Early stopping after 65 epochs.
loading partitions
  NumNodes: 19717
  NumEdges: 88651
  NumFeats: 500
  NumClasses: 3
  NumTrainingSamples: 60
  NumValidationSamples: 500
  NumTestSamples: 1000
Done loading data from cached files.
500
Process 0 has 5930 nodes, 26055 edges 5009 inner nodes, and 22007 inner edges.
Process 000 | Epoch 00004 | Time(s) 0.2244 | Comm(s) 0.0025 | Reduce(s) 0.0002 | Loss 0.6430
Process 000 | Epoch 00009 | Time(s) 0.2115 | Comm(s) 0.0028 | Reduce(s) 0.0002 | Loss 0.5882
Epoch 00004 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00014 | Time(s) 0.2023 | Comm(s) 0.0024 | Reduce(s) 0.0002 | Loss 0.5157
Epoch 00009 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00019 | Time(s) 0.2025 | Comm(s) 0.0019 | Reduce(s) 0.0002 | Loss 0.4262
Epoch 00014 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00024 | Time(s) 0.2018 | Comm(s) 0.0017 | Reduce(s) 0.0002 | Loss 0.6962
Epoch 00019 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00029 | Time(s) 0.2002 | Comm(s) 0.0016 | Reduce(s) 0.0003 | Loss 0.5751
Epoch 00024 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00034 | Time(s) 0.1995 | Comm(s) 0.0014 | Reduce(s) 0.0003 | Loss 0.2968
Epoch 00029 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00039 | Time(s) 0.1977 | Comm(s) 0.0021 | Reduce(s) 0.0003 | Loss 0.2127
Epoch 00034 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00044 | Time(s) 0.1971 | Comm(s) 0.0019 | Reduce(s) 0.0003 | Loss 0.2353
Epoch 00039 | Validation Accuracy 38.80% | Test Accuracy 41.30%
Process 000 | Epoch 00049 | Time(s) 0.1993 | Comm(s) 0.0018 | Reduce(s) 0.0003 | Loss 0.1591
Epoch 00044 | Validation Accuracy 39.20% | Test Accuracy 42.30%
Process 000 | Epoch 00054 | Time(s) 0.1990 | Comm(s) 0.0017 | Reduce(s) 0.0003 | Loss 0.0231
Epoch 00049 | Validation Accuracy 39.20% | Test Accuracy 41.90%
Process 000 | Epoch 00059 | Time(s) 0.1988 | Comm(s) 0.0016 | Reduce(s) 0.0003 | Loss 0.0987
Epoch 00054 | Validation Accuracy 39.40% | Test Accuracy 42.80%
Process 000 | Epoch 00064 | Time(s) 0.1990 | Comm(s) 0.0016 | Reduce(s) 0.0003 | Loss 0.2534
Epoch 00059 | Validation Accuracy 39.80% | Test Accuracy 42.80%
Early stopping after 65 epochs.
Epoch 00064 | Validation Accuracy 40.00% | Test Accuracy 42.70%
Validation accuracy 40.00%
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: \ 0.003 MB of 0.003 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb: average train time per epoch ‚ñÅ
wandb:                best_test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà
wandb:               best_test_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               best_train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà
wandb:              best_train_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 best_val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà
wandb:                best_val_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   num epochs ‚ñÅ
wandb:                     test_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñà‚ñà
wandb:                    test_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñà‚ñá
wandb:                   torch_seed ‚ñà‚ñÅ
wandb:             total train time ‚ñÅ
wandb:     total train time per GPU ‚ñÅ
wandb:         train time per epoch ‚ñÅ
wandb:                    train_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñà
wandb:                   train_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñà‚ñá
wandb:                   train_time ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà
wandb:                      val_acc ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñà
wandb:                     val_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñà‚ñá
wandb: 
wandb: Run summary:
wandb: average train time per epoch 0.19904
wandb:                best_test_acc 0.427
wandb:               best_test_loss 1.35565
wandb:               best_train_acc 0.41667
wandb:              best_train_loss 1.81484
wandb:                 best_val_acc 0.4
wandb:                best_val_loss 1.41955
wandb:                   num epochs 65
wandb:                     test_acc 0.427
wandb:                    test_loss 41.95578
wandb:                   torch_seed 218502625
wandb:             total train time 41.39989
wandb:     total train time per GPU 10.34997
wandb:         train time per epoch 0.63692
wandb:                    train_acc 0.41667
wandb:                   train_loss 67.31152
wandb:                   train_time 14.16145
wandb:                      val_acc 0.4
wandb:                     val_loss 46.34938
wandb: 
wandb: üöÄ View run splendid-sweep-5 at: https://wandb.ai/rl_project_saurabh_arundhati/PipeGCN-pubmed-graphsage/runs/27m1gn39
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230919_000958-27m1gn39/logs
