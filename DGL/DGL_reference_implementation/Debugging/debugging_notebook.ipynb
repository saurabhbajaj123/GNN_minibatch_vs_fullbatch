{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f2a560a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import numpy as np\n",
    "from ogb.nodeproppred import DglNodePropPredDataset, Evaluator\n",
    "import time \n",
    "import numpy as np\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, ReduceLROnPlateau\n",
    "\n",
    "\n",
    "import random\n",
    "import wandb\n",
    "wandb.login()\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn import SAGEConv\n",
    "import tqdm\n",
    "import sklearn.metrics\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler(sys.stdout))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(\n",
    "        self, in_feats, n_hidden, n_classes, n_layers, dropout, activation, aggregator_type='mean'\n",
    "    ):\n",
    "        super(Model, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_classes = n_classes\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(SAGEConv(in_feats, n_hidden, aggregator_type=aggregator_type))\n",
    "        for _ in range(n_layers - 2):\n",
    "            self.layers.append(SAGEConv(n_hidden, n_hidden, aggregator_type=aggregator_type))\n",
    "        self.layers.append(SAGEConv(n_hidden, n_classes, aggregator_type=aggregator_type))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        h = x\n",
    "        for l, conv in enumerate(self.layers):\n",
    "            h = conv(g, h)\n",
    "            # print(\"self.activation = {}\".format(type(self.activation)))\n",
    "            if l != len(self.layers) - 1:\n",
    "                h = self.activation(h)\n",
    "                h = self.dropout(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f370ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _get_data_loader(sampler, device, graph, nids, batch_size=1024):\n",
    "    logger.info(\"Get train-val-test data loader\")\n",
    "    train_nids, valid_nids, test_nids = nids\n",
    "    logger.info(\"Get train data loader\")\n",
    "    train_dataloader = dgl.dataloading.DataLoader(\n",
    "    # The following arguments are specific to DGL's DataLoader.\n",
    "    graph.subgraph(train_nids),              # The graph\n",
    "    train_nids,         # The node IDs to iterate over in minibatches\n",
    "    sampler,            # The neighbor sampler\n",
    "    device=device,      # Put the sampled MFGs on CPU or GPU\n",
    "    # The following arguments are inherited from PyTorch DataLoader.\n",
    "    batch_size=batch_size,    # Batch size\n",
    "    shuffle=True,       # Whether to shuffle the nodes for every epoch\n",
    "    drop_last=False,    # Whether to drop the last incomplete batch\n",
    "    num_workers=0       # Number of sampler processes\n",
    "    )\n",
    "    logger.info(\"Get val data loader\")\n",
    "    valid_dataloader = dgl.dataloading.DataLoader(\n",
    "    graph.subgraph(valid_nids), valid_nids, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    device=device\n",
    "    )\n",
    "\n",
    "    logger.info(\"Get test data loader\")\n",
    "    test_dataloader = dgl.dataloading.DataLoader(\n",
    "    graph.subgraph(test_nids), test_nids, sampler,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    device=device\n",
    "    )\n",
    "\n",
    "    logger.info(\"Train-val-test data loader created\")\n",
    "    \n",
    "    return (train_dataloader, valid_dataloader, test_dataloader)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(evaluator, predictions, labels):\n",
    "    acc = evaluator.eval({\n",
    "        'y_true': torch.reshape(labels, (-1, 1)),\n",
    "        'y_pred': torch.reshape(predictions, (-1, 1)),\n",
    "    })['acc']\n",
    "    # eacc = sklearn.metrics.accuracy_score(labels, predictions)\n",
    "    return acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate2(logits, labels, mask):\n",
    "    logits = logits[mask]\n",
    "    labels = labels[mask]\n",
    "    _, indices = torch.max(logits, dim=1)\n",
    "    correct = torch.sum(indices == labels)\n",
    "    return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "def evaluate3(indices, labels):\n",
    "    # _, indices = torch.max(logits, dim=1)\n",
    "    correct = torch.sum(indices == labels)\n",
    "    return correct.item() * 1.0 / len(labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f68343d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "config={\n",
    "        \"num_epochs\": 10,\n",
    "        \"lr\": 2*1e-3,\n",
    "        \"dropout\": random.uniform(0.3, 0.6),\n",
    "        \"n_hidden\": 1400,\n",
    "        \"n_layers\": 3,\n",
    "        \"agg\": \"mean\",\n",
    "        \"batch_size\": 2**12,\n",
    "        \"budget\": 1000,\n",
    "        }\n",
    "\n",
    "n_layers = config['n_layers']\n",
    "n_hidden = config['n_hidden']\n",
    "num_epochs = config['num_epochs']\n",
    "dropout = config['dropout']\n",
    "batch_size = config['batch_size']\n",
    "lr = config['lr']\n",
    "agg = config['agg']\n",
    "budget = config['budget']\n",
    "\n",
    "root=\"../dataset/\"\n",
    "dataset = DglNodePropPredDataset('ogbn-arxiv', root=root)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "idx_split = dataset.get_idx_split()\n",
    "train_nids = idx_split['train']\n",
    "valid_nids = idx_split['valid']\n",
    "test_nids = idx_split['test']\n",
    "\n",
    "graph, node_labels = dataset[0]\n",
    "graph = dgl.add_reverse_edges(graph)\n",
    "graph.ndata['label'] = node_labels[:, 0]\n",
    "\n",
    "node_features = graph.ndata['feat']\n",
    "in_feats = node_features.shape[1]\n",
    "n_classes = (node_labels.max() + 1).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de1d9152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "169343\n",
      "169343\n"
     ]
    }
   ],
   "source": [
    "t = graph.subgraph(train_nids).ndata['_ID']\n",
    "v = graph.subgraph(valid_nids).ndata['_ID']\n",
    "te = graph.subgraph(test_nids).ndata['_ID']\n",
    "print(len(torch.cat((t,v,te))))\n",
    "print(len(t) + len(v) + len(te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153c4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampler = dgl.dataloading.NeighborSampler([fanout for _ in range(n_layers)])\n",
    "sampler = dgl.dataloading.SAINTSampler(mode='node', budget=budget)\n",
    "\n",
    "data = _get_data_loader(sampler, device, graph, (train_nids, valid_nids, test_nids), batch_size)\n",
    "\n",
    "train_dataloader, valid_dataloader, test_dataloader = data\n",
    "\n",
    "activation = F.relu\n",
    "\n",
    "model = Model(in_feats, n_hidden, n_classes, n_layers, dropout, activation, aggregator_type=agg).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler1 = CosineAnnealingWarmRestarts(optimizer, T_0=50, T_mult=1, eta_min=1e-3)\n",
    "scheduler2 = ReduceLROnPlateau(optimizer, mode='max', factor=0.99, patience=20, min_lr=1e-5)\n",
    "\n",
    "evaluator = Evaluator(name='ogbn-arxiv')\n",
    "best_train_acc = 0\n",
    "best_val_acc = 0\n",
    "best_test_acc = 0\n",
    "\n",
    "best_model_path = 'model.pt'\n",
    "best_model = None\n",
    "total_time = 0\n",
    "\n",
    "time_load = 0\n",
    "time_forward = 0\n",
    "time_backward = 0\n",
    "total_time = 0\n",
    "for epoch in range(num_epochs):\n",
    "    # print(\"epoch = {}\".format(epoch))\n",
    "    model.train()\n",
    "    tic = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    for step, subg in enumerate(train_dataloader):\n",
    "        # print(step)\n",
    "        tic_start = time.time()\n",
    "        inputs = subg.ndata['feat']\n",
    "        labels = subg.ndata['label']\n",
    "        tic_step = time.time()\n",
    "        # print(\"tic_step= {}\".format(tic_step))\n",
    "        predictions = model(subg, inputs)\n",
    "        loss = F.cross_entropy(predictions, labels)\n",
    "        optimizer.zero_grad()\n",
    "        tic_forward = time.time()\n",
    "        # print(\"tic_forward = {}\".format(tic_forward))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        tic_backward = time.time()\n",
    "        # print(\"tic_backward = {}\".format(tic_backward))\n",
    "\n",
    "        time_load += tic_step - tic_start\n",
    "        time_forward += tic_forward - tic_step\n",
    "        time_backward += tic_backward - tic_forward\n",
    "\n",
    "    scheduler2.step(best_val_acc)\n",
    "#     scheduler1.step()\n",
    "    toc = time.time()\n",
    "    total_time += toc - tic\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        # print(\"evalua\")\n",
    "        train_predictions = []\n",
    "        train_labels = []\n",
    "        val_predictions = []\n",
    "        val_labels = []\n",
    "        test_predictions = []\n",
    "        test_labels = []\n",
    "        with torch.no_grad():\n",
    "\n",
    "\n",
    "            pred = model(graph.to(device), graph.ndata['feat'].to(device))\n",
    "\n",
    "            for subg in train_dataloader:\n",
    "                inputs = subg.ndata['feat']\n",
    "                train_labels.append(subg.ndata['label'])\n",
    "                train_predictions.append(model(subg, inputs).argmax(1))\n",
    "            train_predictions = torch.cat(train_predictions)\n",
    "            train_labels = torch.cat(train_labels)\n",
    "            train_acc_subgraph_sample = sklearn.metrics.accuracy_score(train_labels.cpu().numpy(), train_predictions.cpu().numpy())\n",
    "\n",
    "            train_acc_fullgraph_no_sample = evaluate(evaluator, pred[train_nids].argmax(1), graph.ndata['label'][train_nids])\n",
    "\n",
    "            pred_train = model(graph.subgraph(train_nids).to(device), graph.ndata['feat'][train_nids].to(device))\n",
    "            train_acc_subgraph_no_sample = evaluate(evaluator, pred_train.argmax(1), graph.ndata['label'][train_nids])\n",
    "            # train_acc_thru_evaltr = evaluate2(pred, graph.ndata['label'].to(device), train_nids)\n",
    "            # train_acc_thru_evaltr = evaluate3(train_predictions, train_labels)\n",
    "\n",
    "            for subg in valid_dataloader:\n",
    "                inputs = subg.ndata['feat']\n",
    "                val_labels.append(subg.ndata['label'])\n",
    "                val_predictions.append(model(subg, inputs).argmax(1))\n",
    "            val_predictions = torch.cat(val_predictions)\n",
    "            val_labels = torch.cat(val_labels)\n",
    "            val_acc_subgraph_sample = sklearn.metrics.accuracy_score(val_labels.cpu().numpy(), val_predictions.cpu().numpy())\n",
    "\n",
    "            val_acc_fullgraph_no_sample = evaluate(evaluator, pred[valid_nids].argmax(1), graph.ndata['label'][valid_nids])\n",
    "\n",
    "            pred_valid = model(graph.subgraph(valid_nids).to(device), graph.ndata['feat'][valid_nids].to(device))\n",
    "            val_acc_subgraph_no_sample = evaluate(evaluator, pred_valid.argmax(1), graph.ndata['label'][valid_nids])\n",
    "            # val_acc_thru_evaltr = evaluate2(pred, graph.ndata['label'].to(device), valid_nids)\n",
    "            # val_acc_thru_evaltr = evaluate3(val_predictions, val_labels)\n",
    "\n",
    "\n",
    "            for subg in test_dataloader:\n",
    "                inputs = subg.ndata['feat']\n",
    "                test_labels.append(subg.ndata['label'])\n",
    "                test_predictions.append(model(subg, inputs).argmax(1))\n",
    "            test_predictions = torch.cat(test_predictions)\n",
    "            test_labels = torch.cat(test_labels)\n",
    "            test_acc_subgraph_sample = sklearn.metrics.accuracy_score(test_labels.cpu().numpy(), test_predictions.cpu().numpy())\n",
    "\n",
    "            test_acc_fullgraph_no_sample = evaluate(evaluator, pred[test_nids].argmax(1), graph.ndata['label'][test_nids])\n",
    "\n",
    "            pred_test = model(graph.subgraph(test_nids).to(device), graph.ndata['feat'][test_nids].to(device))\n",
    "            test_acc_subgraph_no_sample = evaluate(evaluator, pred_test.argmax(1), graph.ndata['label'][test_nids])\n",
    "            # test_acc_thru_evaltr = evaluate2(pred, graph.ndata['label'].to(device), test_nids)\n",
    "            # test_acc_thru_evaltr = evaluate3(test_predictions, test_labels)\n",
    "\n",
    "\n",
    "\n",
    "            if best_val_acc < val_acc_subgraph_sample:\n",
    "                best_val_acc = val_acc_subgraph_sample\n",
    "                best_model = model\n",
    "                best_test_acc = test_acc_subgraph_sample\n",
    "                best_train_acc = train_acc_subgraph_sample\n",
    "            logger.debug('Epoch {}, Train Acc {:.4f} (Best {:.4f}), Val Acc {:.4f} (Best {:.4f}), Test Acc {:.4f} (Best {:.4f})'.format(epoch, train_acc_subgraph_sample, best_train_acc, val_acc_subgraph_sample, best_val_acc, test_acc_subgraph_sample, best_test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bce3c2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3c8kxmth) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_test_acc</td><td>▁█</td></tr><tr><td>best_train_acc</td><td>▁█</td></tr><tr><td>best_val_acc</td><td>▁█</td></tr><tr><td>lr</td><td>█▁</td></tr><tr><td>test_acc</td><td>▁█</td></tr><tr><td>test_acc_fullgraph_no_sample</td><td>▁█</td></tr><tr><td>test_acc_subgraph_no_sample</td><td>▁█</td></tr><tr><td>test_diff</td><td>▁█</td></tr><tr><td>train_acc</td><td>▁█</td></tr><tr><td>train_acc_fullgraph_no_sample</td><td>▁█</td></tr><tr><td>train_acc_subgraph_no_sample</td><td>▁█</td></tr><tr><td>train_diff</td><td>▁█</td></tr><tr><td>val_acc</td><td>▁█</td></tr><tr><td>val_acc_fullgraph_no_sample</td><td>▁█</td></tr><tr><td>val_acc_subgraph_no_sample</td><td>▁█</td></tr><tr><td>val_diff</td><td>▁█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_test_acc</td><td>0.54799</td></tr><tr><td>best_train_acc</td><td>0.64889</td></tr><tr><td>best_val_acc</td><td>0.55731</td></tr><tr><td>lr</td><td>0.00196</td></tr><tr><td>test_acc</td><td>0.54799</td></tr><tr><td>test_acc_fullgraph_no_sample</td><td>0.57982</td></tr><tr><td>test_acc_subgraph_no_sample</td><td>0.52412</td></tr><tr><td>test_diff</td><td>0.03183</td></tr><tr><td>train_acc</td><td>0.64889</td></tr><tr><td>train_acc_fullgraph_no_sample</td><td>0.56227</td></tr><tr><td>train_acc_subgraph_no_sample</td><td>0.55699</td></tr><tr><td>train_diff</td><td>-0.08663</td></tr><tr><td>val_acc</td><td>0.55731</td></tr><tr><td>val_acc_fullgraph_no_sample</td><td>0.58593</td></tr><tr><td>val_acc_subgraph_no_sample</td><td>0.53821</td></tr><tr><td>val_diff</td><td>0.02862</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">toasty-surf-100</strong> at: <a href='https://wandb.ai/rl_project_saurabh_arundhati/debugging/runs/3c8kxmth' target=\"_blank\">https://wandb.ai/rl_project_saurabh_arundhati/debugging/runs/3c8kxmth</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230427_180932-3c8kxmth/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3c8kxmth). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/GNN_mini_vs_full/GNN_minibatch_vs_fullbatch/DGL/DGL_reference_implementation/Debugging/wandb/run-20230427_181002-v3cwaqir</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rl_project_saurabh_arundhati/debugging/runs/v3cwaqir' target=\"_blank\">flowing-disco-101</a></strong> to <a href='https://wandb.ai/rl_project_saurabh_arundhati/debugging' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rl_project_saurabh_arundhati/debugging' target=\"_blank\">https://wandb.ai/rl_project_saurabh_arundhati/debugging</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rl_project_saurabh_arundhati/debugging/runs/v3cwaqir' target=\"_blank\">https://wandb.ai/rl_project_saurabh_arundhati/debugging/runs/v3cwaqir</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train-val-test data loader\n",
      "Get train-val-test data loader\n",
      "Get train data loader\n",
      "Get train data loader\n",
      "Get val data loader\n",
      "Get val data loader\n",
      "Get test data loader\n",
      "Get test data loader\n",
      "Train-val-test data loader created\n",
      "Train-val-test data loader created\n",
      "Epoch 0, Train Acc 0.4755 (Best 0.4755), Val Acc 0.3977 (Best 0.3977), Test Acc 0.3762 (Best 0.3762)\n",
      "Epoch 0, Train Acc 0.4755 (Best 0.4755), Val Acc 0.3977 (Best 0.3977), Test Acc 0.3762 (Best 0.3762)\n",
      "Epoch 5, Train Acc 0.6527 (Best 0.6527), Val Acc 0.5603 (Best 0.5603), Test Acc 0.5390 (Best 0.5390)\n",
      "Epoch 5, Train Acc 0.6527 (Best 0.6527), Val Acc 0.5603 (Best 0.5603), Test Acc 0.5390 (Best 0.5390)\n",
      "total time for 10 epochs = 1.4333500862121582\n",
      "total time for 10 epochs = 1.4333500862121582\n",
      "avg time per epoch = 0.14333500862121581\n",
      "avg time per epoch = 0.14333500862121581\n"
     ]
    }
   ],
   "source": [
    "val_acc, model = train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285e3792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
